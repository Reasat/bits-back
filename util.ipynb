{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm, beta, binom\n",
    "from scipy.special import gammaln\n",
    "import rans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Statistics functions for encoding and decoding according to uniform and non-\n",
    "# uniform distributions over the integer symbols in range(1 << precision).\n",
    "#\n",
    "# An encoder statfun performs the mapping\n",
    "#     symbol |--> (start, freq)\n",
    "#\n",
    "# A decoder statfun performs the mapping\n",
    "#     cumulative_frequency |--> symbol, (start, freq)\n",
    "# ----------------------------------------------------------------------------\n",
    "uniform_enc_statfun = lambda s: (s, 1)\n",
    "uniform_dec_statfun = lambda cf: (cf, (cf, 1))\n",
    "\n",
    "def uniforms_append(precision):\n",
    "    append_fun = rans.append_symbol(uniform_enc_statfun, precision)\n",
    "    def append(state, symbols):\n",
    "        print('uniforms_append: symbol shape',symbols.shape)\n",
    "        print(symbols)\n",
    "        for symbol in reversed(symbols):\n",
    "            state = append_fun(state, symbol)\n",
    "        return state\n",
    "    return append\n",
    "\n",
    "def uniforms_pop(precision, n):\n",
    "    pop_fun = rans.pop_symbol(uniform_dec_statfun, precision)\n",
    "    def pop(state):\n",
    "        symbols = []\n",
    "        for i in range(n):\n",
    "            state, symbol = pop_fun(state)\n",
    "            symbols.append(symbol)\n",
    "        print('uni_pop: popped symbols shape', np.asarray(symbols).shape)\n",
    "        print(symbols)\n",
    "        return state, np.asarray(symbols)\n",
    "    return pop\n",
    "\n",
    "def non_uniform_enc_statfun(cdf):\n",
    "    def enc(s):\n",
    "        start = cdf(s)\n",
    "        freq = cdf(s + 1) - start\n",
    "        return start, freq\n",
    "    return enc\n",
    "\n",
    "def non_uniform_dec_statfun(ppf, cdf):\n",
    "    def dec(cf):\n",
    "        idx = ppf(cf)\n",
    "        start, freq = non_uniform_enc_statfun(cdf)(idx)\n",
    "        assert start <= cf < start + freq\n",
    "        return idx, (start, freq)\n",
    "    return dec\n",
    "\n",
    "def non_uniforms_append(precision, cdfs):\n",
    "    def append(state, symbols):\n",
    "        print('non_uniforms_append: symbol shape',symbols.shape)\n",
    "        print(symbols)\n",
    "        for symbol, cdf in reversed(list(zip(symbols, cdfs))):\n",
    "            statfun = non_uniform_enc_statfun(cdf)\n",
    "            state = rans.append_symbol(statfun, precision)(state, symbol)\n",
    "        return state\n",
    "    return append\n",
    "\n",
    "def non_uniforms_pop(precision, ppfs, cdfs):\n",
    "    def pop(state):\n",
    "        symbols = []\n",
    "        for ppf, cdf in zip(ppfs, cdfs):\n",
    "            statfun = non_uniform_dec_statfun(ppf, cdf)\n",
    "            state, symbol = rans.pop_symbol(statfun, precision)(state)\n",
    "\n",
    "            symbols.append(symbol)\n",
    "        print('non_uni_pop: popped symbols shape', np.asarray(symbols).shape)\n",
    "        print(symbols)\n",
    "        return state, np.asarray(symbols)\n",
    "    return pop\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Cumulative distribution functions and inverse cumulative distribution\n",
    "# functions (ppf) for discretised Gaussian and Beta latent distributions.\n",
    "#\n",
    "# Latent cdf inputs are indices of buckets of equal width under the 'prior',\n",
    "# assumed for the purposes of bits back to be in the same family. They lie in\n",
    "# the range of ints [0, 1 << prior_prec)\n",
    "#\n",
    "# cdf outputs are scaled and rounded to map to integers in the range of ints\n",
    "# [0, 1 << post_prec) instead of the range [0, 1]\n",
    "#\n",
    "# For decodability we must satisfy\n",
    "#     all(ppf(cf) == s for s in range(1 << prior_prec) for cf in\n",
    "#         range(cdf(s), cdf(s + 1)))\n",
    "# ----------------------------------------------------------------------------\n",
    "def _nearest_int(arr):\n",
    "    # This will break when vectorized\n",
    "    return int(np.around(arr))\n",
    "\n",
    "std_gaussian_bucket_cache = {}  # Stores bucket endpoints\n",
    "std_gaussian_centres_cache = {}  # Stores bucket centres\n",
    "\n",
    "def std_gaussian_buckets(precision):\n",
    "    \"\"\"\n",
    "    Return the endpoints of buckets partioning the domain of the prior. Each\n",
    "    bucket has mass 1 / (1 << precision) under the prior.\n",
    "    \"\"\"\n",
    "    if precision in std_gaussian_bucket_cache:\n",
    "        return std_gaussian_bucket_cache[precision]\n",
    "    else:\n",
    "        buckets = np.float32(\n",
    "            norm.ppf(np.arange(1 << precision + 1) / (1 << precision)))\n",
    "        std_gaussian_bucket_cache[precision] = buckets\n",
    "        return buckets\n",
    "\n",
    "def std_gaussian_centres(precision):\n",
    "    \"\"\"\n",
    "    Return the centres of mass of buckets partioning the domain of the prior.\n",
    "    Each bucket has mass 1 / (1 << precision) under the prior.\n",
    "    \"\"\"\n",
    "    if precision in std_gaussian_centres_cache:\n",
    "        return std_gaussian_centres_cache[precision]\n",
    "    else:\n",
    "        centres = np.float32(\n",
    "            norm.ppf((np.arange(1 << precision) + 0.5) / (1 << precision)))\n",
    "        std_gaussian_centres_cache[precision] = centres\n",
    "        return centres\n",
    "\n",
    "def gaussian_latent_cdf(mean, stdd, prior_prec, post_prec):\n",
    "    def cdf(idx):\n",
    "        x = std_gaussian_buckets(prior_prec)[idx]\n",
    "        return _nearest_int(norm.cdf(x, mean, stdd) * (1 << post_prec))\n",
    "    return cdf\n",
    "\n",
    "def gaussian_latent_ppf(mean, stdd, prior_prec, post_prec):\n",
    "    def ppf(cf):\n",
    "        x = norm.ppf((cf + 0.5) / (1 << post_prec), mean, stdd)\n",
    "        # Binary search is faster than using the actual gaussian cdf for the\n",
    "        # precisions we typically use, however the cdf is O(1) whereas search\n",
    "        # is O(precision), so for high precision cdf will be faster.\n",
    "        return np.searchsorted(\n",
    "            std_gaussian_buckets(prior_prec), x, 'right') - 1\n",
    "    return ppf\n",
    "\n",
    "def beta_latent_cdf(\n",
    "        a_prior, b_prior, a_post, b_post, prior_prec, post_prec):\n",
    "    def cdf(idx):\n",
    "        x = beta.ppf(idx / (1 << prior_prec), a_prior, b_prior)\n",
    "        return _nearest_int(beta.cdf(x, a_post, b_post) * (1 << post_prec))\n",
    "    return cdf\n",
    "\n",
    "def beta_latent_ppf(\n",
    "        a_prior, b_prior, a_post, b_post, prior_prec, post_prec):\n",
    "    def ppf(cf):\n",
    "        x = beta.ppf((cf + 0.5) / (1 << post_prec), a_post, b_post)\n",
    "        return (beta.cdf(x, a_prior, b_prior) * (1 << prior_prec)).astype(int)\n",
    "    return ppf\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Bits back append and pop\n",
    "# ----------------------------------------------------------------------------\n",
    "def bb_ans_append(post_pop, lik_append, prior_append):\n",
    "    def append(state, data):\n",
    "        print('data', data.shape)\n",
    "        print('post_pop')\n",
    "   #     print(state[0])\n",
    "        state, latent = post_pop(data)(state)\n",
    "        print('lik_append')\n",
    "  #      print(state[0], latent)\n",
    "        state = lik_append(latent)(state, data)\n",
    " #       print(state[0])\n",
    "        print('prior_append')\n",
    "        state = prior_append(state, latent)\n",
    "#        print(state[0])\n",
    "        return state\n",
    "    return append\n",
    "\n",
    "def bb_ans_pop(prior_pop, lik_pop, post_append):\n",
    "    def pop(state):\n",
    "        state, latent = prior_pop(state)\n",
    "        state, data = lik_pop(latent)(state)\n",
    "        state = post_append(data)(state, latent)\n",
    "        return state, data\n",
    "    return pop\n",
    "import skimage.io as io\n",
    "def vae_append(latent_shape, gen_net, rec_net, obs_append, prior_prec=8,\n",
    "               latent_prec=12):\n",
    "    \"\"\"\n",
    "    Assume that the vae uses an isotropic Gaussian for its prior and diagonal\n",
    "    Gaussian for its posterior.\n",
    "    \"\"\"\n",
    "    def post_pop(data):\n",
    "        post_mean, post_stdd = rec_net(data)\n",
    "        post_mean, post_stdd = np.ravel(post_mean), np.ravel(post_stdd)\n",
    "        cdfs = [gaussian_latent_cdf(m, s, prior_prec, latent_prec)\n",
    "                for m, s in zip(post_mean, post_stdd)]\n",
    "        ppfs = [gaussian_latent_ppf(m, s, prior_prec, latent_prec)\n",
    "                for m, s in zip(post_mean, post_stdd)]\n",
    "        return non_uniforms_pop(latent_prec, ppfs, cdfs)\n",
    "\n",
    "    def lik_append(latent_idxs):\n",
    "        print('latent_idx', latent_idxs.shape, latent_idxs)\n",
    "        y = std_gaussian_centres(prior_prec)[latent_idxs]\n",
    "        obs_params = gen_net(np.reshape(y, latent_shape))\n",
    "        print('obs_params (with a few elements): ', len(obs_params),obs_params[0].shape, obs_params[:10])\n",
    "#         io.imsave('obs_param_0.png',(obs_params[0]).reshape((28,28)))\n",
    "#         io.imsave('obs_param_1.png',(obs_params[1]).reshape((28,28)))\n",
    "        return obs_append(obs_params)\n",
    "\n",
    "    prior_append = uniforms_append(prior_prec)\n",
    "    return bb_ans_append(post_pop, lik_append, prior_append)\n",
    "\n",
    "def vae_pop(\n",
    "        latent_shape, gen_net, rec_net, obs_pop, prior_prec=8, latent_prec=12):\n",
    "    \"\"\"\n",
    "    Assume that the vae uses an isotropic Gaussian for its prior and diagonal\n",
    "    Gaussian for its posterior.\n",
    "    \"\"\"\n",
    "    prior_pop = uniforms_pop(prior_prec, np.prod(latent_shape))\n",
    "\n",
    "    def lik_pop(latent_idxs):\n",
    "        y = std_gaussian_centres(prior_prec)[latent_idxs]\n",
    "        obs_params = gen_net(np.reshape(y, latent_shape))\n",
    "        return obs_pop(obs_params)\n",
    "\n",
    "    def post_append(data):\n",
    "        post_mean, post_stdd = rec_net(data)\n",
    "        post_mean, post_stdd = np.ravel(post_mean), np.ravel(post_stdd)\n",
    "        cdfs = [gaussian_latent_cdf(m, s, prior_prec, latent_prec)\n",
    "                for m, s in zip(post_mean, post_stdd)]\n",
    "        return non_uniforms_append(latent_prec, cdfs)\n",
    "\n",
    "    return bb_ans_pop(prior_pop, lik_pop, post_append)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Functions for Bernoulli and categorical distributions\n",
    "# ----------------------------------------------------------------------------\n",
    "def create_categorical_buckets(probs, precision):\n",
    "    buckets = np.rint(probs * ((1 << precision) - len(probs))) + np.ones(probs.shape)\n",
    "    print('created buckets from precision and probs: ',buckets)\n",
    "    bucket_sum = sum(buckets)\n",
    "    if not bucket_sum == 1 << precision:\n",
    "        i = np.argmax(buckets)\n",
    "        buckets[i] += (1 << precision) - bucket_sum\n",
    "        print('updated buckets: ',buckets)\n",
    "    assert sum(buckets) == 1 << precision\n",
    "    return np.insert(np.cumsum(buckets), 0, 0)  # this could be slightly wrong\n",
    "\n",
    "def categorical_cdf(probs, precision):\n",
    "    def cdf(s):\n",
    "        cumulative_buckets = create_categorical_buckets(probs, precision)\n",
    "        return int(cumulative_buckets[s])\n",
    "    return cdf\n",
    "\n",
    "def categorical_ppf(probs, precision):\n",
    "    def ppf(cf):\n",
    "        cumulative_buckets = create_categorical_buckets(probs, precision)\n",
    "        return np.searchsorted(cumulative_buckets, cf, 'right') - 1\n",
    "    return ppf\n",
    "\n",
    "def categoricals_append(probs, precision):\n",
    "    \"\"\"Assume that the last dim of probs contains the probability vectors,\n",
    "    i.e. np.sum(probs, axis=-1) == ones\"\"\"\n",
    "    # Flatten all but last dim of probs\n",
    "    probs = np.reshape(probs, (-1, np.shape(probs)[-1]))\n",
    "    cdfs = [categorical_cdf(p, precision) for p in probs]\n",
    "    def append(state, data):\n",
    "        data = np.ravel(data)\n",
    "        return non_uniforms_append(precision, cdfs)(state, data)\n",
    "    return append\n",
    "\n",
    "def categoricals_pop(probs, precision):\n",
    "    \"\"\"Assume that the last dim of probs contains the probability vectors,\n",
    "    i.e. np.sum(probs, axis=-1) == ones\"\"\"\n",
    "    # Flatten all but last dim of probs\n",
    "    data_shape = np.shape(probs)[:-1]\n",
    "    probs = np.reshape(probs, (-1, np.shape(probs)[-1]))\n",
    "    cdfs = [categorical_cdf(p, precision) for p in probs]\n",
    "    ppfs = [categorical_ppf(p, precision) for p in probs]\n",
    "\n",
    "    def pop(state):\n",
    "        state, symbols = non_uniforms_pop(precision, ppfs, cdfs)(state)\n",
    "        return state, np.reshape(symbols, data_shape)\n",
    "    return pop\n",
    "\n",
    "def bernoullis_append(probs, precision):\n",
    "    return categoricals_append(np.stack((1 - probs, probs), axis=-1), precision)\n",
    "\n",
    "def bernoullis_pop(probs, precision):\n",
    "    return categoricals_pop(np.stack((1 - probs, probs), axis=-1), precision)\n",
    "\n",
    "def binomial_cdf(n, p, precision):\n",
    "    def cdf(k):\n",
    "        return _nearest_int(binom.cdf(k - 1, n, p) * (1 << precision))\n",
    "    return cdf\n",
    "\n",
    "def binomial_ppf(n, p, precision):\n",
    "    def ppf(cf):\n",
    "        return np.int64(binom.ppf((cf + 0.5) / (1 << precision), n, p))\n",
    "    return ppf\n",
    "\n",
    "def beta_binomial_log_pdf(k, n, a, b):\n",
    "    a_plus_b = a + b\n",
    "    numer = (gammaln(n + 1) + gammaln(k + a) + gammaln(n - k + b)\n",
    "             + gammaln(a_plus_b))\n",
    "    denom = (gammaln(k + 1) + gammaln(n - k + 1) + gammaln(n + a_plus_b)\n",
    "             + gammaln(a) + gammaln(b))\n",
    "    return numer - denom\n",
    "\n",
    "def generate_beta_binomial_probs(a, b, n):\n",
    "    ks = np.arange(n + 1)\n",
    "    a = a[..., np.newaxis]\n",
    "    b = b[..., np.newaxis]\n",
    "    probs = np.exp(beta_binomial_log_pdf(ks, n, a, b))\n",
    "    # make sure normalised, there are some numerical\n",
    "    # issues with the exponentiation in the beta binomial\n",
    "    probs = np.clip(probs, 1e-10, 1.)\n",
    "    return probs / np.sum(probs, axis=-1, keepdims=True)\n",
    "\n",
    "def beta_binomials_append(a, b, n, precision):\n",
    "    # TODO: Implement this using bits-back instead of generic discrete distrn.\n",
    "    print('beta_binomials_append: ')\n",
    "    print('a,b,n,precision:', a,b,n,precision)\n",
    "    probs = generate_beta_binomial_probs(a, b, n)\n",
    "    print('probs: ', probs.shape, probs)\n",
    "    return categoricals_append(probs, precision)\n",
    "\n",
    "def beta_binomials_pop(a, b, n, precision):\n",
    "    # TODO: Implement this using bits-back instead of generic discrete distrn.\n",
    "    probs = generate_beta_binomial_probs(a, b, n)\n",
    "    return categoricals_pop(probs, precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([       -inf, -1.5341206 , -1.1503494 , -0.88714653, -0.67448974,\n",
       "       -0.48877642, -0.31863937, -0.15731068,  0.        ,  0.15731068,\n",
       "        0.31863937,  0.48877642,  0.67448974,  0.88714653,  1.1503494 ,\n",
       "        1.5341206 ,         inf,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buckets = std_gaussian_buckets(4)\n",
    "buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.8627318 , -1.3180109 , -1.0099902 , -0.7764218 , -0.57913214,\n",
       "       -0.40225005, -0.23720211, -0.07841241,  0.07841241,  0.23720211,\n",
       "        0.40225005,  0.57913214,  0.7764218 ,  1.0099902 ,  1.3180109 ,\n",
       "        1.8627318 ], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers = std_gaussian_centres(4)\n",
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([       -inf, -1.8627318 , -1.5341206 , -1.3180109 , -1.1503494 ,\n",
       "       -1.0099902 , -0.88714653, -0.7764218 , -0.67448974, -0.57913214,\n",
       "       -0.48877642, -0.40225005, -0.31863937, -0.23720211, -0.15731068,\n",
       "       -0.07841241,  0.        ,  0.07841241,  0.15731068,  0.23720211,\n",
       "        0.31863937,  0.40225005,  0.48877642,  0.57913214,  0.67448974,\n",
       "        0.7764218 ,  0.88714653,  1.0099902 ,  1.1503494 ,  1.3180109 ,\n",
       "        1.5341206 ,  1.8627318 ,         inf,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buckets = std_gaussian_buckets(5)\n",
    "buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.1538746 , -1.6759397 , -1.4177971 , -1.2298588 , -1.0775156 ,\n",
       "       -0.94678175, -0.83051085, -0.72451437, -0.626099  , -0.5334097 ,\n",
       "       -0.44509652, -0.3601299 , -0.27769044, -0.19709909, -0.11776987,\n",
       "       -0.03917608,  0.03917608,  0.11776987,  0.19709909,  0.27769044,\n",
       "        0.3601299 ,  0.44509652,  0.5334097 ,  0.626099  ,  0.72451437,\n",
       "        0.83051085,  0.94678175,  1.0775156 ,  1.2298588 ,  1.4177971 ,\n",
       "        1.6759397 ,  2.1538746 ], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers = std_gaussian_centres(5)\n",
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = np.array([0.2,0.3,0.5,0.6,0.7,0.8])\n",
    "prec = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created buckets from precision and probs:  [3. 4. 6. 7. 8. 9.]\n",
      "updated buckets:  [  3.   4.   6.   7.   8. -12.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  3.,  7., 13., 20., 28., 16.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_categorical_buckets(prob,prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 4., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.rint(prob * ((1 << prec) - len(prob))) + np.ones(prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 3., 5., 6., 7., 8.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.rint(prob * ((1 << prec) - len(prob))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 << prec) - len(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.2,  4.8,  8. ,  9.6, 11.2, 12.8])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(prob * ((1 << prec))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_vae.tvae_beta_binomial import BetaBinomialVAE\n",
    "from torch_vae import tvae_utils\n",
    "import torch\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "np.seterr(over='raise')\n",
    "\n",
    "prior_precision = 8\n",
    "obs_precision = 14\n",
    "q_precision = 14\n",
    "\n",
    "num_images = 100\n",
    "\n",
    "compress_lengths = []\n",
    "\n",
    "latent_dim = 50\n",
    "latent_shape = (1, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = BetaBinomialVAE(hidden_dim=200, latent_dim=latent_dim)\n",
    "model.load_state_dict(\n",
    "    torch.load('torch_vae/saved_params/torch_vae_beta_binomial_params',\n",
    "               map_location=lambda storage, location: storage))\n",
    "model.eval()\n",
    "\n",
    "rec_net = tvae_utils.torch_fun_to_numpy_fun(model.encode)\n",
    "gen_net = tvae_utils.torch_fun_to_numpy_fun(model.decode)\n",
    "\n",
    "obs_append = tvae_utils.beta_binomial_obs_append(255, obs_precision)\n",
    "obs_pop = tvae_utils.beta_binomial_obs_pop(255, obs_precision)\n",
    "\n",
    "vae_append = util.vae_append(latent_shape, gen_net, rec_net, obs_append,\n",
    "                             prior_precision, q_precision)\n",
    "vae_pop = util.vae_pop(latent_shape, gen_net, rec_net, obs_pop,\n",
    "                       prior_precision, q_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
